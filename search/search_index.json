{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Using ML with Amazon SageMaker & GuardDuty to identify anomalous traffic Welcome! This guide provides instructions and pointers to the resources used for the workshop. Level : Intermediate Duration : 2 hours CAF Components : Detective, Responsive Prerequisites : Active email address, Modern, graphical web browser This documents helps you get started with the Jam Platform and then walks your through the following exercises: Enabling Amazon GuardDuty and exploring GuarDuty findings Using AWS Lambda to transform data so it is suitable for model training and inference IP-based anomaly detection in SageMaker Initial setup Prerequisites You do not need an AWS account for this workshop. You will be using the AWS Jam Platform to access a temporary AWS account to run the lab. Modern, graphical web browser - sorry Lynx users :) After the workshop, you can deploy the CloudFormation template, located in the GitHub repository, into your own AWS account if you'd like to explore the workshop exercises further! You may use the following CloudFormation Stack Launch URLs to quickly launch the stack into the AWS account into which you are currently signed in through your web browser: US Oregon (us-west-2): https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=AWS-ML-Detection-Workshop&templateURL=https://aws-workshop-security-ml-threat-detection.s3-us-west-2.amazonaws.com/cloudformation.yaml Last region used: https://console.aws.amazon.com/cloudformation/home?region=#/stacks/new?stackName=AWS-ML-Detection-Workshop&templateURL=https://aws-workshop-security-ml-threat-detection.s3-us-west-2.amazonaws.com/cloudformation.yaml Before getting started, you will need to setup an account on the AWS Jam Platform. - If you do not already have a Jam account, you will need an active email address to register - Go to https://jam.awsevents.com/ and enroll in an account - Your Workshop Facilitator will give you the Secret Key necessary to access today's Jam Event Welcome the Jam Platform For this workshop, there will be only one \"Jam Challenge\" available to you in the Jam Console. - Please click on the challenge titled, Who was that IP address I saw you with last night? - You will see a brief description of the lab. - Click on View Details , and you will a longer summary of the lab. Go ahead and read this, and then... - Click on the blue Start Challenge button. You will see a pop-up message that says, This challenge is still deploying. Please check back soon. It will take a few minutes for the Jam Platform to create and provision your temporary account for the lab. In the meantime, your facilitators will take some time to walk through some key concepts in the lab. When the Workshop Facilitator tells you to begin, you can refresh this page in the web browser. You should now see an option near the top to Open AWS Console (blue button). If you click this button, a new browser tab should open in your new, temporary AWS account. Exercise 1: Examining GuardDuty findings In this exercise, you will generate and examine sample GuardDuty findings to understand what information they contain, and then also look at several \"real\" GuardDuty findings that were generated from actual AWS account activity. The goal of this exercise is to familiarize with the kinds of information contained in GuardDuty findings, and the structure of the findings themselves. 1.1 Generate sample findings From the Services dropdown in the top left, browse to the GuardDuty console (just type \"GuardDuty\" into the search box). Verify that you are in the US West (Oregon) region via the region dropdown in the top right; if not, please switch to that region. GuardDuty should not yet be enabled in this account. Click the Get Started button in the middle of the screen. Next, click the button labelled Enable GuardDuty to turn it on with a single click. In the left menu click Settings , scroll down to the section titled \"Sample Findings\", then click on the button labelled Generate sample findings to generate a sample GuardDuty finding for every finding type. Click on Findings in the left menu and examine some of the sample findings shown in the GuardDuty console. What kinds of information do you see? Examine some of the findings with a threat purpose of \"UnauthorizedAccess\". 1.2 Examining real findings The \"real\" GuardDuty findings that were generated for this workshop are contained in an S3 bucket as JSON. Rather than look at them in S3, we're going to run the AWS Lambda ingester function for the GuardDuty findings that will read in the findings from the S3 bucket and print them out. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"GuardDutyIngestLambda\" (it will end with some random hexadecimal characters). Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template, give it the name \"Workshop\", then click Create . You then need to click the Test button once more. Examine the output, where you'll see the JSON for each GuardDuty finding being printed by the function print_full_finding . Look over the findings to see what information they contain. A function called print_short_finding is also defined to print out a shortened, one-line version of each GuardDuty finding. Replace the call to the function print_full_finding with print_short_finding (hint: Search for \"TODO\" around line 135. You will see multiple TODOs in the file, but only the first one applies here.). Click the Save button at the top of the screen to save your changes to the function, then click Test to run it again. Observe the new output, where you will now see a summarized version of each finding being printed. Exercise 2: Using AWS Lambda to transform data so it is suitable for model training and inference In this exercise, you will use AWS to transform our data. In real-world ML/Data Science projects, the data exploration and transofrmation is a critical part of the solution, and often requires a significant time investment. For this lab, we're going to simplify things for you, and just give you a flavor of the data preparation process. You will use two Lambda functions to prepare the input data for the ML algorithm from the source CloudTrail and GuardDuty log data. You will generate training data consisting of <principal ID, IP address> tuples from the CloudTrail logs and then you will call the trained model to make inferences to score the GuardDuty findings from Exercise 1 by using a similar set of tuples generated from the findings. The GuardDuty findings are based on the same set of account activity as the CloudTrail logs. 2.1 Generate training data using CloudTrail logs In order to use the IP Insights model, we need some training data. We will train the model by passing <principal ID, IP address> tuples extracted from CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"CloudTrailIngestLambda\" (it will end with some random hexadecimal characters). Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it the name \"Workshop\", then click Create . You then need to click the Test button once more. Look at the output of the function, where you'll see a short version of each CloudTrail record returned by the function print_short_record being printed. A function get_tuple has been provided to take a CloudTrail record as input and return a <principal ID, IP address> tuple for each record. A call to this function has already been set up in the handler function, but the lines are commented out (hint: search for the string \"TODO\"). Uncomment the lines. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it will write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for training the model. In the S3 console, go into the bucket whose name contains the string \"tuplesbucket\" (just before the random characters on the end of the bucket name). You should now see a file \"train/cloudtrail_tuples.csv\" inside that contains some <principal ID, IP address> tuples. 2.2 Generate scoring data using GuardDuty findings To make use of the trained model, we will pass <principal ID, IP address> tuples extracted from the GuardDuty findings to it for scoring (i.e., inference). The activity contained in these GuardDuty findings directly corresponds to the activity contained in the CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"GuardDutyIngestLambda\" (it will end with some random hexadecimal characters). A function get_tuples has been provided to take GuardDuty findings as input and return <principal ID, IP address> tuples for each finding. A call to this function has already been set up in the handler function (search for the string \"TODO\"), but the line is commented out. Uncomment it. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for scoring. In the S3 console, go into the bucket whose name contains the string \"tuplesbucket\" (just before the random characters on the end of the bucket name). You should now see a file \"infer/guardduty_tuples.csv\" inside that contains some <principal ID, IP address> tuples. Exercise 3: IP-based anomaly detection in SageMaker Now, it's time to build a machine learning model with SageMaker. The IP Insights SageMaker machine learning algorithm will use the CloudTrail data we've prepared to learn what \"normal\" IP address usage looks like, and then we'll see how the IP addresses coming from GuardDuty appear to that model - how anomalous they look. 3.1 Set up the SageMaker notebook To use the IP Insights algorithm, you will work from a Jupyter notebook, which is an interactive coding environment that lets you mix notes and documentation with code blocks that can be \"run\" in a stepwise fashion throughout the notebook and share the same interpreter. Browse to the Amazon SageMaker console and click on the button called Create notebook instance . You will have to fill in a Notebook Instance Name in the top box: use \"AWS-SecML-Detection\" For Notebook instance type, leave the default value (ml.t2.medium). Leave the Elastic Inference box set to \"None\" In Permissions and Encryption , for IAM role, choose \"Enter a Customer IAM role arn\" in the dropdown. Copy/paste this string into the arn parameter arn:aws:iam::[ACCTNUMBER]:role/MLSecWorkshopSageMakerRole You'll need to paste your account number into this string before proceeding. The Jam Platform makes this easy... Go back to the Jam console and on the left-hand side menu, click the link called AWS Account . Copy the 12-digit account number shown in the center of the page. This account number will match what is shown from the top-right dropdown in the AWS console. Paste the account number into the ARN back in the SageMaker notebook console in place of the string [ACCTNUMBER] . Your final ARN string should look like this: arn:aws:iam::123456789012:role/MLSecWorkshopSageMakerRole All other notebook options can be left at defaults. Click Create notebook instance . It will take about 5 minutes for the instances and notebook to be ready. (You might have to refresh your browser tab to see the status update.) Once the notebook is running, click Open Jupyter to open the notebook. We have a prepared notebook for you to use. First, Download the sample notebook file for the workshop where we will be working with the IP Insights algorithm: https://s3.us-west-2.amazonaws.com/aws-workshop-security-ml-threat-detection/mlsec-workshop-ipinsights.ipynb . This will download the notebook file to your local machine. Within the Jupyter console, click the Upload button on the upper right hand side in Jupyter to upload the notebook. Once uploaded, click on the notebook name, and it will open in a new browser tab. 3.2 Training and scoring with the IP Insights algorithm Click on the notebook and work through it step by step to learn how to train the model using the tuples from the CloudTrail logs and then make inferences by scoring the tuples from the GuardDuty findings. We recommend using the \"Run\" command to walk through each code block one by one rather than doing \"Run All\". IP Insights is an unsupervised learning algorithm for detecting anomalous behavior and usage patterns of IP addresses, that helps users identifying fraudulent behavior using IP addresses, describe the Amazon SageMaker IP Insights algorithm, demonstrate how you can use it in a real-world application, and share some of our results using it internally. For more information about the IP Insights algorithm, please read the following AWS blog post: https://aws.amazon.com/blogs/machine-learning/detect-suspicious-ip-addresses-with-the-amazon-sagemaker-ip-insights-algorithm/ You can also view the IP Insights documentation here: https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html 3.2.1 (BONUS) IP Insights algorithm tutorial If you would like to experiment with the IP Insights algorithm using a much larger dataset, you can choose the SageMaker Examples tab in Jupyter to see a list of all the Amazon SageMaker examples. Expand the Introduction to Amazon Algorithms section, look for a notebook called ipinsights-tutorial.ipynb , then click its Use button and Create copy in the dialog to create a copy of it, then work through it step by step. How can I reuse the artifacts in this lab? All of the code and artifacts used in this lab - including these instructions, but not including the Jam Platform - are available in a public GitHub repository . There you will find the following files: aws_lambda/ cloudtrail_ingest.zip - Lambda zip bundle for workshop CloudTrail log ingest guardduty_ingest.zip - Lambda zip bundle for workshop GuardDuty finding ingest templates/ cloudformation.yaml - The CloudFormation template to deploy the stack of resources for the workshop mlsec-participant-policy.json - The IAM policy specifying the permissions needed for the lab user mlsec-workshop-ipinsights.ipynb - Jupyter notebook for the workshop to load into SageMaker CLEANUP.md - Instructions on cleaning up the CloudFormation stack (not needed if using Jam Platform) cleanup.sh - Shell script to delete the workshop CloudFormation stack at the end (not needed if using Jam Platform)","title":"Workshop"},{"location":"#using-ml-with-amazon-sagemaker-guardduty-to-identify-anomalous-traffic","text":"Welcome! This guide provides instructions and pointers to the resources used for the workshop. Level : Intermediate Duration : 2 hours CAF Components : Detective, Responsive Prerequisites : Active email address, Modern, graphical web browser This documents helps you get started with the Jam Platform and then walks your through the following exercises: Enabling Amazon GuardDuty and exploring GuarDuty findings Using AWS Lambda to transform data so it is suitable for model training and inference IP-based anomaly detection in SageMaker","title":"Using ML with Amazon SageMaker &amp; GuardDuty to identify anomalous traffic"},{"location":"#initial-setup","text":"","title":"Initial setup"},{"location":"#prerequisites","text":"You do not need an AWS account for this workshop. You will be using the AWS Jam Platform to access a temporary AWS account to run the lab. Modern, graphical web browser - sorry Lynx users :) After the workshop, you can deploy the CloudFormation template, located in the GitHub repository, into your own AWS account if you'd like to explore the workshop exercises further! You may use the following CloudFormation Stack Launch URLs to quickly launch the stack into the AWS account into which you are currently signed in through your web browser: US Oregon (us-west-2): https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=AWS-ML-Detection-Workshop&templateURL=https://aws-workshop-security-ml-threat-detection.s3-us-west-2.amazonaws.com/cloudformation.yaml Last region used: https://console.aws.amazon.com/cloudformation/home?region=#/stacks/new?stackName=AWS-ML-Detection-Workshop&templateURL=https://aws-workshop-security-ml-threat-detection.s3-us-west-2.amazonaws.com/cloudformation.yaml Before getting started, you will need to setup an account on the AWS Jam Platform. - If you do not already have a Jam account, you will need an active email address to register - Go to https://jam.awsevents.com/ and enroll in an account - Your Workshop Facilitator will give you the Secret Key necessary to access today's Jam Event","title":"Prerequisites"},{"location":"#welcome-the-jam-platform","text":"For this workshop, there will be only one \"Jam Challenge\" available to you in the Jam Console. - Please click on the challenge titled, Who was that IP address I saw you with last night? - You will see a brief description of the lab. - Click on View Details , and you will a longer summary of the lab. Go ahead and read this, and then... - Click on the blue Start Challenge button. You will see a pop-up message that says, This challenge is still deploying. Please check back soon. It will take a few minutes for the Jam Platform to create and provision your temporary account for the lab. In the meantime, your facilitators will take some time to walk through some key concepts in the lab. When the Workshop Facilitator tells you to begin, you can refresh this page in the web browser. You should now see an option near the top to Open AWS Console (blue button). If you click this button, a new browser tab should open in your new, temporary AWS account.","title":"Welcome the Jam Platform"},{"location":"#exercise-1-examining-guardduty-findings","text":"In this exercise, you will generate and examine sample GuardDuty findings to understand what information they contain, and then also look at several \"real\" GuardDuty findings that were generated from actual AWS account activity. The goal of this exercise is to familiarize with the kinds of information contained in GuardDuty findings, and the structure of the findings themselves.","title":"Exercise 1: Examining GuardDuty findings"},{"location":"#11-generate-sample-findings","text":"From the Services dropdown in the top left, browse to the GuardDuty console (just type \"GuardDuty\" into the search box). Verify that you are in the US West (Oregon) region via the region dropdown in the top right; if not, please switch to that region. GuardDuty should not yet be enabled in this account. Click the Get Started button in the middle of the screen. Next, click the button labelled Enable GuardDuty to turn it on with a single click. In the left menu click Settings , scroll down to the section titled \"Sample Findings\", then click on the button labelled Generate sample findings to generate a sample GuardDuty finding for every finding type. Click on Findings in the left menu and examine some of the sample findings shown in the GuardDuty console. What kinds of information do you see? Examine some of the findings with a threat purpose of \"UnauthorizedAccess\".","title":"1.1 Generate sample findings"},{"location":"#12-examining-real-findings","text":"The \"real\" GuardDuty findings that were generated for this workshop are contained in an S3 bucket as JSON. Rather than look at them in S3, we're going to run the AWS Lambda ingester function for the GuardDuty findings that will read in the findings from the S3 bucket and print them out. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"GuardDutyIngestLambda\" (it will end with some random hexadecimal characters). Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template, give it the name \"Workshop\", then click Create . You then need to click the Test button once more. Examine the output, where you'll see the JSON for each GuardDuty finding being printed by the function print_full_finding . Look over the findings to see what information they contain. A function called print_short_finding is also defined to print out a shortened, one-line version of each GuardDuty finding. Replace the call to the function print_full_finding with print_short_finding (hint: Search for \"TODO\" around line 135. You will see multiple TODOs in the file, but only the first one applies here.). Click the Save button at the top of the screen to save your changes to the function, then click Test to run it again. Observe the new output, where you will now see a summarized version of each finding being printed.","title":"1.2 Examining real findings"},{"location":"#exercise-2-using-aws-lambda-to-transform-data-so-it-is-suitable-for-model-training-and-inference","text":"In this exercise, you will use AWS to transform our data. In real-world ML/Data Science projects, the data exploration and transofrmation is a critical part of the solution, and often requires a significant time investment. For this lab, we're going to simplify things for you, and just give you a flavor of the data preparation process. You will use two Lambda functions to prepare the input data for the ML algorithm from the source CloudTrail and GuardDuty log data. You will generate training data consisting of <principal ID, IP address> tuples from the CloudTrail logs and then you will call the trained model to make inferences to score the GuardDuty findings from Exercise 1 by using a similar set of tuples generated from the findings. The GuardDuty findings are based on the same set of account activity as the CloudTrail logs.","title":"Exercise 2: Using AWS Lambda to transform data so it is suitable for model training and inference"},{"location":"#21-generate-training-data-using-cloudtrail-logs","text":"In order to use the IP Insights model, we need some training data. We will train the model by passing <principal ID, IP address> tuples extracted from CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"CloudTrailIngestLambda\" (it will end with some random hexadecimal characters). Scroll down to view the code for the Lambda function in the inline, browser-based editor. Skim through the code to familiarize with what it does. Click the Test button to run the function. You will need to create a test event to do this, but the event actually does not matter in this case, so just use the \"Hello World\" event template and give it the name \"Workshop\", then click Create . You then need to click the Test button once more. Look at the output of the function, where you'll see a short version of each CloudTrail record returned by the function print_short_record being printed. A function get_tuple has been provided to take a CloudTrail record as input and return a <principal ID, IP address> tuple for each record. A call to this function has already been set up in the handler function, but the lines are commented out (hint: search for the string \"TODO\"). Uncomment the lines. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it will write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for training the model. In the S3 console, go into the bucket whose name contains the string \"tuplesbucket\" (just before the random characters on the end of the bucket name). You should now see a file \"train/cloudtrail_tuples.csv\" inside that contains some <principal ID, IP address> tuples.","title":"2.1 Generate training data using CloudTrail logs"},{"location":"#22-generate-scoring-data-using-guardduty-findings","text":"To make use of the trained model, we will pass <principal ID, IP address> tuples extracted from the GuardDuty findings to it for scoring (i.e., inference). The activity contained in these GuardDuty findings directly corresponds to the activity contained in the CloudTrail logs. An AWS Lambda function has been created to do this, but you'll need to make a small change to the function and then run it to generate the tuples. Browse to the AWS Lambda console and click on the Lambda function whose name contains the string \"GuardDutyIngestLambda\" (it will end with some random hexadecimal characters). A function get_tuples has been provided to take GuardDuty findings as input and return <principal ID, IP address> tuples for each finding. A call to this function has already been set up in the handler function (search for the string \"TODO\"), but the line is commented out. Uncomment it. Click the Save button at the top to save your function changes. Click the Test button to run the function again. This time it write the tuples to the S3 bucket where they can be loaded into the IP Insights algorithm for scoring. In the S3 console, go into the bucket whose name contains the string \"tuplesbucket\" (just before the random characters on the end of the bucket name). You should now see a file \"infer/guardduty_tuples.csv\" inside that contains some <principal ID, IP address> tuples.","title":"2.2 Generate scoring data using GuardDuty findings"},{"location":"#exercise-3-ip-based-anomaly-detection-in-sagemaker","text":"Now, it's time to build a machine learning model with SageMaker. The IP Insights SageMaker machine learning algorithm will use the CloudTrail data we've prepared to learn what \"normal\" IP address usage looks like, and then we'll see how the IP addresses coming from GuardDuty appear to that model - how anomalous they look.","title":"Exercise 3: IP-based anomaly detection in SageMaker"},{"location":"#31-set-up-the-sagemaker-notebook","text":"To use the IP Insights algorithm, you will work from a Jupyter notebook, which is an interactive coding environment that lets you mix notes and documentation with code blocks that can be \"run\" in a stepwise fashion throughout the notebook and share the same interpreter. Browse to the Amazon SageMaker console and click on the button called Create notebook instance . You will have to fill in a Notebook Instance Name in the top box: use \"AWS-SecML-Detection\" For Notebook instance type, leave the default value (ml.t2.medium). Leave the Elastic Inference box set to \"None\" In Permissions and Encryption , for IAM role, choose \"Enter a Customer IAM role arn\" in the dropdown. Copy/paste this string into the arn parameter arn:aws:iam::[ACCTNUMBER]:role/MLSecWorkshopSageMakerRole You'll need to paste your account number into this string before proceeding. The Jam Platform makes this easy... Go back to the Jam console and on the left-hand side menu, click the link called AWS Account . Copy the 12-digit account number shown in the center of the page. This account number will match what is shown from the top-right dropdown in the AWS console. Paste the account number into the ARN back in the SageMaker notebook console in place of the string [ACCTNUMBER] . Your final ARN string should look like this: arn:aws:iam::123456789012:role/MLSecWorkshopSageMakerRole All other notebook options can be left at defaults. Click Create notebook instance . It will take about 5 minutes for the instances and notebook to be ready. (You might have to refresh your browser tab to see the status update.) Once the notebook is running, click Open Jupyter to open the notebook. We have a prepared notebook for you to use. First, Download the sample notebook file for the workshop where we will be working with the IP Insights algorithm: https://s3.us-west-2.amazonaws.com/aws-workshop-security-ml-threat-detection/mlsec-workshop-ipinsights.ipynb . This will download the notebook file to your local machine. Within the Jupyter console, click the Upload button on the upper right hand side in Jupyter to upload the notebook. Once uploaded, click on the notebook name, and it will open in a new browser tab.","title":"3.1 Set up the SageMaker notebook"},{"location":"#32-training-and-scoring-with-the-ip-insights-algorithm","text":"Click on the notebook and work through it step by step to learn how to train the model using the tuples from the CloudTrail logs and then make inferences by scoring the tuples from the GuardDuty findings. We recommend using the \"Run\" command to walk through each code block one by one rather than doing \"Run All\". IP Insights is an unsupervised learning algorithm for detecting anomalous behavior and usage patterns of IP addresses, that helps users identifying fraudulent behavior using IP addresses, describe the Amazon SageMaker IP Insights algorithm, demonstrate how you can use it in a real-world application, and share some of our results using it internally. For more information about the IP Insights algorithm, please read the following AWS blog post: https://aws.amazon.com/blogs/machine-learning/detect-suspicious-ip-addresses-with-the-amazon-sagemaker-ip-insights-algorithm/ You can also view the IP Insights documentation here: https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html","title":"3.2 Training and scoring with the IP Insights algorithm"},{"location":"#321-bonus-ip-insights-algorithm-tutorial","text":"If you would like to experiment with the IP Insights algorithm using a much larger dataset, you can choose the SageMaker Examples tab in Jupyter to see a list of all the Amazon SageMaker examples. Expand the Introduction to Amazon Algorithms section, look for a notebook called ipinsights-tutorial.ipynb , then click its Use button and Create copy in the dialog to create a copy of it, then work through it step by step.","title":"3.2.1 (BONUS) IP Insights algorithm tutorial"},{"location":"#how-can-i-reuse-the-artifacts-in-this-lab","text":"All of the code and artifacts used in this lab - including these instructions, but not including the Jam Platform - are available in a public GitHub repository . There you will find the following files: aws_lambda/ cloudtrail_ingest.zip - Lambda zip bundle for workshop CloudTrail log ingest guardduty_ingest.zip - Lambda zip bundle for workshop GuardDuty finding ingest templates/ cloudformation.yaml - The CloudFormation template to deploy the stack of resources for the workshop mlsec-participant-policy.json - The IAM policy specifying the permissions needed for the lab user mlsec-workshop-ipinsights.ipynb - Jupyter notebook for the workshop to load into SageMaker CLEANUP.md - Instructions on cleaning up the CloudFormation stack (not needed if using Jam Platform) cleanup.sh - Shell script to delete the workshop CloudFormation stack at the end (not needed if using Jam Platform)","title":"How can I reuse the artifacts in this lab?"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"}]}